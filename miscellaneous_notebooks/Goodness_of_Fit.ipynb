{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# HIDDEN\n",
    "from datascience import *\n",
    "from prob140 import *\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('fivethirtyeight')\n",
    "%matplotlib inline\n",
    "import math\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chi-Squared Test for \"Goodness of Fit\" ###\n",
    "Recall the Alameda County jury selection example from Data 8. There were $c=5$ categories of jurors. In the language of Prob140, for each $i$ the eligible population proportion in Category $i$ was a known value $p_i$, with $\\sum_{i=1}^c p_i = 1$. \n",
    "\n",
    "The jurors on the panels were a sample of size $n$ from the eligible population. The question was whether sample looked as if it had been drawn at random.\n",
    "\n",
    "In Data 8 we used total variation distance as our test statistic:\n",
    "$$\n",
    "TVD_{obs} = \\frac{1}{2} \\sum_{i=1}^c \\lvert p_i^* - p_i \\rvert\n",
    "$$\n",
    "where for each $i$, $p_i^*$ was the observed proportion in Category $i$.\n",
    "\n",
    "We comapared this observed test statistic to values of the statistic simulated under the null hypothesis of randomness:\n",
    "\n",
    "$$\n",
    "TVD_{null} = \\frac{1}{2} \\sum_{i=1}^c \\lvert \\hat{p}_i - p_i \\rvert\n",
    "$$\n",
    "where $\\hat{p}_i$ was the proportion in Category $i$ in a random sample of size $n$.\n",
    "\n",
    "Here we will examine the classical test of the same null hypothesis of randomness. Under the null, the expected count in Category $i$ is $np_i$. Let the observed count be $N_i$, with $\\sum_{i=1}^c N_i = n$, the total sample size. The *chi-squared test statistic* is defined as\n",
    "\n",
    "$$\n",
    "\\chi^2 ~ = ~ \\sum_{categories} \\frac{(\\text{observed count - expected count})^2}{\\text{expected count}} ~ = ~ \\sum_{i=1}^c \\frac{(N_i - np_i)^2}{np_i}\n",
    "$$\n",
    "\n",
    "Under the null hypothesis, the joint distribution of $(N_1, N_2, \\ldots, N_c)$ is multinomial with parameters $n$ and $p_1, p_2, \\ldots, p_c$.\n",
    "\n",
    "From this it can be shown that under the null hypothesis, the distribution of $\\chi^2$ is approximately chi-squared with $c-1$ degrees of freedom. So you can compare the observed value of $\\chi^2$ with the chi-squared $(c-1)$ distribution to determine a $p$-value. You will do that as part of your next lab.\n",
    "\n",
    "Here we will simply indicate how the $\\chi^2$ statistic as defined above has an approximate chi-squared $c-1$ distribution, by examining the simple case where there are only two categories. This is a binomial setting, like the Swain vs. Alabama example in Data 8, where you are counting how many 1's there are in your sample, the rest being 0's.\n",
    "\n",
    "Let's set up some notation and make a few observations.\n",
    "\n",
    "- Call the two categories 0 and 1. \n",
    "- Under the null hypothesis, let the probability of 1 be $p$ and hence let the probability of 0 be $q = 1-p$.\n",
    "- Then under the null, the distribution of $N_0$ is binomial $(n, q)$ and the distribution of $N_1$ is binomial $(n, p)$.\n",
    "\n",
    "The chi-squared test statistic is\n",
    "$$\n",
    "\\chi^2 ~ = ~ \\frac{(N_0 - nq)^2}{nq} + \\frac{(N_1 - np)^2}{np}\n",
    "$$\n",
    "\n",
    "Observe that\n",
    "$$\n",
    "N_0 - nq ~ = ~ (n - N_1) - nq ~ = ~ np - N_1\n",
    "$$\n",
    "\n",
    "So the chi-squared statistic becomes\n",
    "\n",
    "\\begin{align*}\n",
    "\\chi^2 &= \\frac{(N_0 - nq)^2}{nq} + \\frac{(N_1 - np)^2}{np} \\\\ \\\\\n",
    "&= \\frac{(N_1 - np)^2}{n} \\big{(} \\frac{1}{q} + \\frac{1}{p} \\big{)} \\\\ \\\\\n",
    "&= \\frac{(N_1 - np)^2}{n} \\big{(} \\frac{p+q}{pq} \\big{)} \\\\ \\\\\n",
    "&= \\frac{(N_1 - np)^2}{npq} \\\\ \\\\\n",
    "&= \\Big{(} \\frac{N_1 - np}{\\sqrt{npq}} \\Big{)}^2\n",
    "\\end{align*}\n",
    "\n",
    "Under the null hypothesis, the quantity inside the square is a standardized binomial random variable. If the sample size $n$ is large, its distribution is approximately standard normal. \n",
    "\n",
    "Therefore if the sample size is large, the distribution of the $\\chi^2$ statistic is approximately chi-squared with 1 degree of freedom."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the number of categories $c$ is greater than 2, a more complex calculation is required. We won't go into it in this course. Just note that the array of counts $(N_1, N_2, \\ldots, N_c)$ in the $c$ categories is a $c-1$ dimensional vector as the sum of all the counts has to be the sample size which is fixed in advance. This motivates the terminology: there are only $c-1$ \"degrees of freedom\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Notes. ####\n",
    "- This test is called the *chi-squared test for goodness of fit*. It is a test of how well the model of random draws from a known categorical distribution fits the data.\n",
    "- The test requires a large sample, because it relies on the normal approximation to multinomial counts. By contrast, the Data 8 test that uses the TVD works for small samples too.\n",
    "- Whether you use the chi-squared statistic or the TVD, you will have trouble with accuracy if the population proportion in any category happens to be small. You are unlikely to get an adequate proportion of sampled individuals in that category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
